Project 7: Identification of lower extremity injuries from jump-landings videos: A Deep
Learning Approach



Our literature references:


A Framework for Biomechanical Analysis of Jump Landings for Injury Risk Assessment
S Sharma, S Divakaran, T Kaya, C Taber, MS Raval - 2023 IEEE 28th Pacific Rim International
Symposium ..., 2023
https://ahduni.edu.in/site/assets/files/6912/paper_38.pdf

Other supplementary material:

● Hébert-Losier K, Hanzlíková I, Zheng C, Streeter L, Mayo M. The ‘DEEP’ Landing
Error Scoring System. Applied Sciences. 2020; 10(3):892.
https://doi.org/10.3390/app10030892

● Padua, D. A., Marshall, S. W., Boling, M. C., Thigpen, C. A., Garrett Jr, W. E., &
Beutler, A. I. (2009). The Landing Error Scoring System (LESS) is a valid and reliable
clinical assessment tool of jump-landing biomechanics: the JUMP-ACL study. The
American journal of sports medicine, 37(10), 1996-2002.

Problem Statement

Competitive sports demand rapid high-intensity movements requiring exceptional physical
fitness, stamina and flexibility. Prolonged high-intensity repetitive exercises and asymmetric
postures increase the risk of injuries in athletes [1]. This increased risk is attributed to altered or
reduced neuromuscular control during sports movements, leading to changes in lower limb joint
mechanics, including motions and loads [2]. Landing is one such frequent movement in a sport
like basketball.

Progress

So far, we have not finalized our approach, we have finished our literature survey and started scouting various deep learning architectures which would help us align with our goal of identifying lower extremity injuries.

Secondly, we have received the dataset for our project, which includes jump landing videos of athletes from the frontal and the sagittal (lateral) plane. The IC frame and the MKF (maximum knee flexion) are the frames of interest to us. Hence, we have looked for the methods to separate those frames of interest from the video dataset. 

Lastly, we have to show visualizations of landing errors using annotated videos and hence we have started exploring Kinova for that part.

